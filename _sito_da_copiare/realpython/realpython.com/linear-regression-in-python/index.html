
<!doctype html>
<html lang="en">
<head>
<link href="https://cdn.realpython.com" rel="preconnect">
<link href="https://files.realpython.com" rel="preconnect">
<title>Linear Regression in Python – Real Python</title>
<meta name="author" content="Real Python">
<meta name="description" content="In this step-by-step tutorial, you&#x27;ll get started with linear regression in Python. Linear regression is one of the fundamental statistical and machine learning techniques, and Python is a popular choice for machine learning.">
<meta name="keywords" content="">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, viewport-fit=cover">
<link rel="stylesheet" href="https://cdn.realpython.com/static/realpython.min.1ecfd4a9d422.css">
<link rel="stylesheet" href="https://cdn.realpython.com/static/gfonts/font.08e909e5f3d4.css">
<link rel="preload" href="https://cdn.realpython.com/static/glightbox.min.f69035b3cab2.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="https://cdn.realpython.com/static/glightbox.min.f69035b3cab2.css"></noscript>
<link rel="canonical" href="https://realpython.com/linear-regression-in-python/">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg">
<meta property="og:image" content="https://files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg">
<meta name="twitter:creator" content="@realpython">
<meta name="twitter:site" content="@realpython">
<meta property="og:title" content="Linear Regression in Python – Real Python">
<meta property="og:type" content="article">
<meta property="og:url" content="https://realpython.com/linear-regression-in-python/">
<meta property="og:description" content="In this step-by-step tutorial, you&#x27;ll get started with linear regression in Python. Linear regression is one of the fundamental statistical and machine learning techniques, and Python is a popular choice for machine learning.">
<link href="https://cdn.realpython.com/static/favicon.68cbf4197b0c.png" rel="icon">
<link href="https://realpython.com/atom.xml" rel="alternate" title="Real Python" type="application/atom+xml">
<link rel="manifest" href="/manifest.json">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-35184939-1', 'auto', {'allowLinker': true});

  
    ga('set', 'anonymizeIp', true);
  

  

  
  
  ga('set', {
    dimension1: false,
    dimension2: false
  });
  

  ga('send', 'pageview');
  
</script>
<script async src='/cdn-cgi/challenge-platform/h/b/scripts/invisible.js'></script></head>
<body>
<nav class="navbar fixed-top navbar-expand-lg navbar-dark flex-column ">
<div class="container flex-row">
<a class="navbar-brand" href="/">
<img src="https://cdn.realpython.com/static/real-python-logo.893c30edea53.svg" width="165" height="40" class="d-inline-block align-top" alt="Real Python">
</a>
<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
<span class="navbar-toggler-icon"></span>
</button>
<div class="collapse navbar-collapse navbar-nav-scroll" id="navbarSupportedContent" role="navigation" aria-label="Main Navigation">
<ul class="navbar-nav mr-2 flex-fill">
<li class="nav-item">
<a class="nav-link" href="/start-here/">Start&nbsp;Here</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownLibrary" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
<span class="fa fa-graduation-cap" aria-hidden="true"></span> Learn Python
</a>
<div class="dropdown-menu" aria-labelledby="navbarDropdownLibrary">
<a class="dropdown-item" href="/" style="color: #ff7e73; line-height: 110%;"><i class="fa fa-fw mr-1 fa-graduation-cap" aria-hidden="true"></i> Python Tutorials →<br><small class="text-secondary">In-depth articles and tutorials</small></a>
<a class="dropdown-item" href="/courses/" style="color: #abe5b1; line-height: 110%;"><i class="fa fa-fw mr-1 fa-film" aria-hidden="true"></i> Video Courses →<br><small class="text-secondary">Step-by-step video lessons</small></a>
<a class="dropdown-item" href="/quizzes/" style="color: #abe0e5; line-height: 110%;"><i class="fa fa-fw mr-1 fa-trophy" aria-hidden="true"></i> Quizzes →<br><small class="text-secondary">Check your learning progress</small></a>
<a class="dropdown-item" href="/learning-paths/" style="color: #ffc873; line-height: 110%;"><i class="fa fa-fw mr-1 fa-map-o" aria-hidden="true"></i> Learning Paths →<br><small class="text-secondary">Guided study plans for accelerated learning</small></a>
<a class="dropdown-item" href="/community/" style="color: #e5c6ab; line-height: 110%;"><i class="fa fa-fw mr-1 fa-slack" aria-hidden="true"></i> Community →<br><small class="text-secondary">Learn with other Pythonistas</small></a>
<a class="dropdown-item pb-3" href="/tutorials/all/" style="color: #b8abe5; line-height: 110%;"><i class="fa fa-fw mr-1 fa-tags" aria-hidden="true"></i> Topics →<br><small class="text-secondary">Focus on a specific area or skill level</small></a>
<a class="dropdown-item border-top" href="/account/join/"><i class="fa fa-fw fa-star text-warning" aria-hidden="true"></i> Unlock All Content</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownBooksCourses" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
Store
</a>
<div class="dropdown-menu" aria-labelledby="navbarDropdownBooksCourses">
<a class="dropdown-item" href="/account/join/"><i class="fa fa-fw fa-star text-warning" aria-hidden="true"></i> RP Membership</a>
<a class="dropdown-item" href="/products/python-basics-book/">Python Basics Book</a>
<a class="dropdown-item" href="/products/python-tricks-book/">Python Tricks Book</a>
<a class="dropdown-item" href="/products/cpython-internals-book/">CPython Internals Book</a>
<a class="dropdown-item" href="/products/real-python-course/">The Real Python Course</a>
<a class="dropdown-item" href="/products/managing-python-dependencies/">Managing Python Dependencies</a>
<a class="dropdown-item" href="/products/sublime-python/">Sublime Text + Python Setup</a>
<a class="dropdown-item" href="/products/pythonic-wallpapers/">Pythonic Wallpapers Pack</a>
<a class="dropdown-item" href="https://nerdlettering.com" target="_blank">Python Mugs, T-Shirts, and More</a>
<a class="dropdown-item" href="https://www.pythonistacafe.com" target="_blank">Pythonista Cafe Community</a>
<a class="dropdown-item border-top" href="/products/">Browse All »</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMore" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
More
</a>
<div class="dropdown-menu" aria-labelledby="navbarDropdownMore">
<a class="dropdown-item" href="/newsletter/">Python Newsletter</a>
<a class="dropdown-item" href="/podcasts/rpp/">Python Podcast</a>
<a class="dropdown-item" href="https://www.pythonjobshq.com" target="_blank">Python Job Board</a>
<a class="dropdown-item" href="/team/">Meet the Team</a>
<a class="dropdown-item" href="/write-for-us/">Become a Tutorial Author</a>
<a class="dropdown-item" href="/become-an-instructor/">Become a Video Instructor</a>
</div>
</li>
</ul>
<div class="d-block d-xl-none">
<ul class="navbar-nav">
<li class="nav-item">
<a class="nav-link" href="/search" title="Search"><span class="d-block d-lg-none"><i class="fa fa-search" aria-hidden="true"></i> Search</span><span class="d-none d-lg-block"><i class="fa fa-search" aria-hidden="true"></i></span></a>
</li>
</ul>
</div>
<div class="d-none d-xl-flex align-items-center mr-2">
<form class="form-inline" action="/search" method="GET">
<a class="js-search-form-submit position-absolute" href="/search" title="Search"><i class="fa fa-search fa-fw text-muted pl-2" aria-hidden="true"></i></a>
<input class="search-field form-control form-control-md mr-sm-1 mr-lg-2 w-100" style="padding-left: 2rem;" maxlength=50 type="search" placeholder="Search" aria-label="Search" name="q">
<input type="hidden" name="_from" value="nav">
</form>
</div>
<ul class="navbar-nav">
<li class="nav-item form-inline">
<a class="ml-2 ml-lg-0 btn btn-sm btn-primary px-3" href="/account/join/">Join</a>
</li>
<li class="nav-item">
<a class="btn text-light" href="/account/login/?next=%2Flinear-regression-in-python%2F">Sign&#8209;In</a>
</li>
</ul>
</div>
</div>
</nav>
<div class="container main-content">
<div class="row justify-content-center">
<div class="col-md-11 col-lg-8 article with-headerlinks">
<figure class="embed-responsive embed-responsive-16by9">
<img class="card-img-top m-0 p-0 embed-responsive-item rounded" style="object-fit: contain;" alt="Linear Regression in Python" src="https://files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg" width="1920" height="1080" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg&amp;w=480&amp;sig=3be4751287a71577f0b247ddeb74eca56610f78d 480w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg&amp;w=960&amp;sig=e30f8718b654654a64fdd74e39a62aa507f06595 960w, https://files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg 1920w" sizes="75vw">
</figure>
<h1>Linear Regression in Python</h1>
<div class="mb-0">
<span class="text-muted">by <a class="text-muted" href="#author">Mirko Stojiljković</a>
<span class="ml-2 mr-1 fa fa-comments"></span><a class="text-muted" href="#reader-comments"><span class="disqus-comment-count" data-disqus-identifier="https://realpython.com/linear-regression-in-python/"></span></a>
<span class="ml-2 fa fa-tags" aria-hidden="true"></span>
<a href="/tutorials/data-science/" class="badge badge-light text-muted">data-science</a>
<a href="/tutorials/intermediate/" class="badge badge-light text-muted">intermediate</a>
<a href="/tutorials/machine-learning/" class="badge badge-light text-muted">machine-learning</a>
<div class="d-sm-flex flex-row justify-content-between my-3 text-center">
<div class="jsCompletionStatusWidget btn-group mb-0">
<button title="Click to mark as completed" class="jsBtnCompletion btn btn-secondary border-right " style="border-top-right-radius: 0; border-bottom-right-radius: 0;" disabled>Mark as Completed</button>
<button title="Add bookmark" class="jsBtnBookmark btn btn-secondary border-left" disabled><i class="fa fa-fw fa-bookmark-o"></i></button>
</div>
<div class="align-self-center my-2">
<span>
<a target="_blank" rel="nofollow" href="https://twitter.com/intent/tweet/?text=Check out this %23Python tutorial: Linear%20Regression%20in%20Python by @realpython&url=https%3A//realpython.com/linear-regression-in-python/" class="mr-1 badge badge-twitter text-light mb-1"><i class="mr-1 fa fa-twitter text-light"></i>Tweet</a>
<a target="_blank" rel="nofollow" href="https://facebook.com/sharer/sharer.php?u=https%3A//realpython.com/linear-regression-in-python/" class="mr-1 badge badge-facebook text-light mb-1"><i class="mr-1 fa fa-facebook text-light"></i>Share</a>
<a target="_blank" rel="nofollow" href="mailto:?subject=Python article for you&body=Check out this Python tutorial:%0A%0ALinear%20Regression%20in%20Python%0A%0Ahttps%3A//realpython.com/linear-regression-in-python/" class="badge badge-red text-light mb-1"><i class="mr-1 fa fa-envelope text-light"></i>Email</a>
</span>
</div>
</div>
</div>
<div class="article-body">
<div class="bg-light sidebar-module sidebar-module-inset" id="toc">
<p class="h3 mb-2 text-muted">Table of Contents</p>
<div class="toc">
<ul>
<li><a href="#regression">Regression</a><ul>
<li><a href="#what-is-regression">What Is Regression?</a></li>
<li><a href="#when-do-you-need-regression">When Do You Need Regression?</a></li>
</ul>
</li>
<li><a href="#linear-regression">Linear Regression</a><ul>
<li><a href="#problem-formulation">Problem Formulation</a></li>
<li><a href="#regression-performance">Regression Performance</a></li>
<li><a href="#simple-linear-regression">Simple Linear Regression</a></li>
<li><a href="#multiple-linear-regression">Multiple Linear Regression</a></li>
<li><a href="#polynomial-regression">Polynomial Regression</a></li>
<li><a href="#underfitting-and-overfitting">Underfitting and Overfitting</a></li>
</ul>
</li>
<li><a href="#implementing-linear-regression-in-python">Implementing Linear Regression in Python</a><ul>
<li><a href="#python-packages-for-linear-regression">Python Packages for Linear Regression</a></li>
<li><a href="#simple-linear-regression-with-scikit-learn">Simple Linear Regression With scikit-learn</a></li>
<li><a href="#multiple-linear-regression-with-scikit-learn">Multiple Linear Regression With scikit-learn</a></li>
<li><a href="#polynomial-regression-with-scikit-learn">Polynomial Regression With scikit-learn</a></li>
<li><a href="#advanced-linear-regression-with-statsmodels">Advanced Linear Regression With statsmodels</a></li>
</ul>
</li>
<li><a href="#beyond-linear-regression">Beyond Linear Regression</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</div>
</div>
<div class="sidebar-module sidebar-module-inset p-0" style="overflow:hidden;">
<div style="display:block;position:relative;">
<div style="display:block;width:100%;padding-top:12.5%;"></div>
<div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div>
</div>
<a class="small text-muted" href="/account/join/" rel="nofollow"> <i class="fa fa-info-circle" aria-hidden="true"> </i> Remove ads</a>
</div>
<p>We&rsquo;re living in the era of large amounts of <a href="https://realpython.com/tutorials/data-science/">data</a>, powerful computers, and <a href="https://realpython.com/python-ai-neural-network/">artificial intelligence</a>. This is just the beginning. <a href="https://realpython.com/data-science-podcasts/">Data science</a> and machine learning are driving image recognition, autonomous vehicles development, decisions in the financial and energy sectors, advances in medicine, the rise of social networks, and more. Linear regression is an important part of this.</p>
<p>Linear regression is one of the fundamental statistical and machine learning techniques. Whether you want to do <a href="https://realpython.com/python-statistics/">statistics</a>, <a href="https://realpython.com/tutorials/machine-learning/">machine learning</a>, or scientific computing, there are good chances that you&rsquo;ll need it. It&rsquo;s advisable to learn it first and then proceed towards more complex methods.</p>
<p><strong>By the end of this article, you&rsquo;ll have learned:</strong></p>
<ul>
<li>What linear regression is</li>
<li>What linear regression is used for</li>
<li>How linear regression works</li>
<li>How to implement linear regression in Python, step by step</li>
</ul>
<div class="alert alert-warning" role="alert"><p><strong>Free Bonus:</strong> <a href="#" class="alert-link" data-toggle="modal" data-target="#modal-numpy-learning-guide" data-focus="false">Click here to get access to a free NumPy Resources Guide</a> that points you to the best tutorials, videos, and books for improving your NumPy skills.</p></div>
<section class="section2" id="regression"><h2>Regression<a class="headerlink" href="#regression" title="Permanent link"></a></h2>
<p>Regression analysis is one of the most important fields in statistics and machine learning. There are many regression methods available. Linear regression is one of them.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div><section class="section3" id="what-is-regression"><h3>What Is Regression?<a class="headerlink" href="#what-is-regression" title="Permanent link"></a></h3>
<p>Regression searches for relationships among <a href="https://realpython.com/python-variables/">variables</a>.</p>
<p>For example, you can observe several employees of some company and try to understand how their salaries depend on the <strong>features</strong>, such as experience, level of education, role, city they work in, and so on.</p>
<p>This is a regression problem where data related to each employee represent one <strong>observation</strong>. The presumption is that the experience, education, role, and city are the independent features, while the salary depends on them.</p>
<p>Similarly, you can try to establish a mathematical dependence of the prices of houses on their areas, numbers of bedrooms, distances to the city center, and so on.</p>
<p>Generally, in regression analysis, you usually consider some phenomenon of interest and have a number of observations. Each observation has two or more features. Following the assumption that (at least) one of the features depends on the others, you try to establish a relation among them.</p>
<p>In other words, <strong>you need to find a function that maps some features or variables to others sufficiently well</strong>.</p>
<p>The dependent features are called the <strong>dependent variables</strong>, <strong>outputs</strong>, or <strong>responses</strong>.</p>
<p>The independent features are called the <strong>independent variables</strong>, <strong>inputs</strong>, or <strong>predictors</strong>.</p>
<p>Regression problems usually have one continuous and unbounded dependent variable. The inputs, however, can be continuous, discrete, or even categorical data such as gender, nationality, brand, and so on.</p>
<p>It is a common practice to denote the outputs with 𝑦 and inputs with 𝑥. If there are two or more independent variables, they can be represented as the vector 𝐱 = (𝑥₁, …, 𝑥ᵣ), where 𝑟 is the number of inputs.</p>
</section><section class="section3" id="when-do-you-need-regression"><h3>When Do You Need Regression?<a class="headerlink" href="#when-do-you-need-regression" title="Permanent link"></a></h3>
<p>Typically, you need regression to answer whether and how some phenomenon influences the other or <strong>how several variables are related</strong>. For example, you can use it to determine <em>if</em> and <em>to what extent</em> the experience or gender impact salaries.</p>
<p>Regression is also useful when you want <strong>to forecast a response</strong> using a new set of predictors. For example, you could try to predict electricity consumption of a household for the next hour given the outdoor temperature, time of day, and number of residents in that household.</p>
<p>Regression is used in many different fields: economy, computer science, social sciences, and so on. Its importance rises every day with the availability of large amounts of data and increased awareness of the practical value of data.</p>
</section></section><section class="section2" id="linear-regression"><h2>Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link"></a></h2>
<p>Linear regression is probably one of the most important and widely used regression techniques. It&rsquo;s among the simplest regression methods. One of its main advantages is the ease of interpreting results.</p>
<section class="section3" id="problem-formulation"><h3>Problem Formulation<a class="headerlink" href="#problem-formulation" title="Permanent link"></a></h3>
<p>When implementing linear regression of some dependent variable 𝑦 on the set of independent variables 𝐱 = (𝑥₁, …, 𝑥ᵣ), where 𝑟 is the number of predictors, you assume a linear relationship between 𝑦 and 𝐱: 𝑦 = 𝛽₀ + 𝛽₁𝑥₁ + ⋯ + 𝛽ᵣ𝑥ᵣ + 𝜀. This equation is the <strong>regression equation</strong>. 𝛽₀, 𝛽₁, …, 𝛽ᵣ are the <strong>regression coefficients</strong>, and 𝜀 is the <strong>random error</strong>.</p>
<p>Linear regression calculates the <strong>estimators</strong> of the regression coefficients or simply the <strong>predicted weights</strong>, denoted with 𝑏₀, 𝑏₁, …, 𝑏ᵣ. They define the <strong>estimated regression function</strong> 𝑓(𝐱) = 𝑏₀ + 𝑏₁𝑥₁ + ⋯ + 𝑏ᵣ𝑥ᵣ. This function should capture the dependencies between the inputs and output sufficiently well.</p>
<p>The <strong>estimated</strong> or <strong>predicted response</strong>, 𝑓(𝐱ᵢ), for each observation 𝑖 = 1, …, 𝑛, should be as close as possible to the corresponding <strong>actual response</strong> 𝑦ᵢ. The differences 𝑦ᵢ - 𝑓(𝐱ᵢ) for all observations 𝑖 = 1, …, 𝑛, are called the <strong>residuals</strong>. Regression is about determining the <strong>best predicted weights</strong>, that is the weights corresponding to the smallest residuals.</p>
<p>To get the best weights, you usually <strong>minimize the sum of squared residuals</strong> (SSR) for all observations 𝑖 = 1, …, 𝑛: SSR = Σᵢ(𝑦ᵢ - 𝑓(𝐱ᵢ))². This approach is called the <strong>method of ordinary least squares</strong>.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section><section class="section3" id="regression-performance"><h3>Regression Performance<a class="headerlink" href="#regression-performance" title="Permanent link"></a></h3>
<p>The variation of actual responses 𝑦ᵢ, 𝑖 = 1, …, 𝑛, occurs partly due to the dependence on the predictors 𝐱ᵢ. However, there is also an additional inherent variance of the output.</p>
<p>The <strong>coefficient of determination</strong>, denoted as 𝑅², tells you which amount of variation in 𝑦 can be explained by the dependence on 𝐱 using the particular regression model. Larger 𝑅² indicates a better fit and means that the model can better explain the variation of the output with different inputs.</p>
<p>The value 𝑅² = 1 corresponds to SSR = 0, that is to the <strong>perfect fit</strong> since the values of predicted and actual responses fit completely to each other.</p>
</section><section class="section3" id="simple-linear-regression"><h3>Simple Linear Regression<a class="headerlink" href="#simple-linear-regression" title="Permanent link"></a></h3>
<p>Simple or single-variate linear regression is the simplest case of linear regression with a single independent variable, 𝐱 = 𝑥.</p>
<p>The following figure illustrates simple linear regression:</p>
<figure class="js-lightbox"><a href="https://files.realpython.com/media/fig-lin-reg.a506035b654a.png" target="_blank"><img loading="lazy" class="img-fluid mx-auto d-block " src="https://files.realpython.com/media/fig-lin-reg.a506035b654a.png" width="950" height="481" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/fig-lin-reg.a506035b654a.png&amp;w=237&amp;sig=ccb74ab08d560aceb779a10de4507db4f97000be 237w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/fig-lin-reg.a506035b654a.png&amp;w=475&amp;sig=dfa9f07896d01e38bb307a25b45ca82dee604c8b 475w, https://files.realpython.com/media/fig-lin-reg.a506035b654a.png 950w" sizes="75vw" alt="Example of simple linear regression" data-asset="1172" /></a><figcaption class="figure-caption text-center">Example of simple linear regression</figcaption></figure>
<p>When implementing simple linear regression, you typically start with a given set of input-output (𝑥-𝑦) pairs (green circles). These pairs are your observations. For example, the leftmost observation (green circle) has the input 𝑥 = 5 and the actual output (response) 𝑦 = 5. The next one has 𝑥 = 15 and 𝑦 = 20, and so on.</p>
<p>The estimated regression function (black line) has the equation 𝑓(𝑥) = 𝑏₀ + 𝑏₁𝑥. Your goal is to calculate the optimal values of the predicted weights 𝑏₀ and 𝑏₁ that minimize SSR and determine the estimated regression function. The value of 𝑏₀, also called the <strong>intercept</strong>, shows the point where the estimated regression line crosses the 𝑦 axis. It is the value of the estimated response 𝑓(𝑥) for 𝑥 = 0. The value of 𝑏₁ determines the <strong>slope</strong> of the estimated regression line.</p>
<p>The predicted responses (red squares) are the points on the regression line that correspond to the input values. For example, for the input 𝑥 = 5, the predicted response is 𝑓(5) = 8.33 (represented with the leftmost red square).</p>
<p>The residuals (vertical dashed gray lines) can be calculated as 𝑦ᵢ - 𝑓(𝐱ᵢ) = 𝑦ᵢ - 𝑏₀ - 𝑏₁𝑥ᵢ for 𝑖 = 1, …, 𝑛. They are the distances between the green circles and red squares. When you implement linear regression, you are actually trying to minimize these distances and make the red squares as close to the predefined green circles as possible.</p>
</section><section class="section3" id="multiple-linear-regression"><h3>Multiple Linear Regression<a class="headerlink" href="#multiple-linear-regression" title="Permanent link"></a></h3>
<p>Multiple or multivariate linear regression is a case of linear regression with two or more independent variables.</p>
<p>If there are just two independent variables, the estimated regression function is 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂. It represents a regression plane in a three-dimensional space. The goal of regression is to determine the values of the weights 𝑏₀, 𝑏₁, and 𝑏₂ such that this plane is as close as possible to the actual responses and yield the minimal SSR.</p>
<p>The case of more than two independent variables is similar, but more general. The estimated regression function is 𝑓(𝑥₁, …, 𝑥ᵣ) = 𝑏₀ + 𝑏₁𝑥₁ + ⋯ +𝑏ᵣ𝑥ᵣ, and there are 𝑟 + 1 weights to be determined when the number of inputs is 𝑟.</p>
</section><section class="section3" id="polynomial-regression"><h3>Polynomial Regression<a class="headerlink" href="#polynomial-regression" title="Permanent link"></a></h3>
<p>You can regard polynomial regression as a generalized case of linear regression. You assume the polynomial dependence between the output and inputs and, consequently, the polynomial estimated regression function.</p>
<p>In other words, in addition to linear terms like 𝑏₁𝑥₁, your regression function 𝑓 can include non-linear terms such as 𝑏₂𝑥₁², 𝑏₃𝑥₁³, or even 𝑏₄𝑥₁𝑥₂, 𝑏₅𝑥₁²𝑥₂, and so on.</p>
<p>The simplest example of polynomial regression has a single independent variable, and the estimated regression function is a polynomial of degree 2: 𝑓(𝑥) = 𝑏₀ + 𝑏₁𝑥 + 𝑏₂𝑥².</p>
<p>Now, remember that you want to calculate 𝑏₀, 𝑏₁, and 𝑏₂, which minimize SSR. These are your unknowns! </p>
<p>Keeping this in mind, compare the previous regression function with the function 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂ used for linear regression. They look very similar and are both linear functions of the unknowns 𝑏₀, 𝑏₁, and 𝑏₂. This is why you can <strong>solve the polynomial regression problem as a linear problem</strong> with the term 𝑥² regarded as an input variable.</p>
<p>In the case of two variables and the polynomial of degree 2, the regression function has this form: 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂ + 𝑏₃𝑥₁² + 𝑏₄𝑥₁𝑥₂ + 𝑏₅𝑥₂². The procedure for solving the problem is identical to the previous case. You apply linear regression for five inputs: 𝑥₁, 𝑥₂, 𝑥₁², 𝑥₁𝑥₂, and 𝑥₂². What you get as the result of regression are the values of six weights which minimize SSR: 𝑏₀, 𝑏₁, 𝑏₂, 𝑏₃, 𝑏₄, and 𝑏₅.</p>
<p>Of course, there are more general problems, but this should be enough to illustrate the point.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section><section class="section3" id="underfitting-and-overfitting"><h3>Underfitting and Overfitting<a class="headerlink" href="#underfitting-and-overfitting" title="Permanent link"></a></h3>
<p>One very important question that might arise when you&rsquo;re implementing polynomial regression is related to <strong>the choice of the optimal degree of the polynomial regression function</strong>.</p>
<p>There is no straightforward rule for doing this. It depends on the case. You should, however, be aware of two problems that might follow the choice of the degree: <strong>underfitting</strong> and <strong>overfitting</strong>.</p>
<p><strong>Underfitting</strong> occurs when a model can&rsquo;t accurately capture the dependencies among data, usually as a consequence of its own simplicity. It often yields a low 𝑅² with known data and bad generalization capabilities when applied with new data.</p>
<p><strong>Overfitting</strong> happens when a model learns both dependencies among data and random fluctuations. In other words, a model learns the existing data too well. Complex models, which have many features or terms, are often prone to overfitting. When applied to known data, such models usually yield high 𝑅². However, they often don&rsquo;t generalize well and have significantly lower 𝑅² when used with new data.</p>
<p>The next figure illustrates the underfitted, well-fitted, and overfitted models:</p>
<figure class="js-lightbox"><a href="https://files.realpython.com/media/poly-reg.5790f47603d8.png" target="_blank"><img loading="lazy" class="img-fluid mx-auto d-block " src="https://files.realpython.com/media/poly-reg.5790f47603d8.png" width="946" height="933" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/poly-reg.5790f47603d8.png&amp;w=236&amp;sig=785372237ae2c73a587d77619f23edbc4834a8a0 236w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/poly-reg.5790f47603d8.png&amp;w=473&amp;sig=be83466567e91dc253f2040eb9ea907ca1617fdf 473w, https://files.realpython.com/media/poly-reg.5790f47603d8.png 946w" sizes="75vw" alt="Example of underfitted, well-fitted and overfitted models" data-asset="1173" /></a><figcaption class="figure-caption text-center">Example of underfitted, well-fitted and overfitted models</figcaption></figure>
<p>The top left plot shows a linear regression line that has a low 𝑅². It might also be important that a straight line can&rsquo;t take into account the fact that the actual response increases as 𝑥 moves away from 25 towards zero. This is likely an example of underfitting.</p>
<p>The top right plot illustrates polynomial regression with the degree equal to 2. In this instance, this might be the optimal degree for modeling this data. The model has a value of 𝑅² that is satisfactory in many cases and shows trends nicely.</p>
<p>The bottom left plot presents polynomial regression with the degree equal to 3. The value of 𝑅² is higher than in the preceding cases. This model behaves better with known data than the previous ones. However, it shows some signs of overfitting, especially for the input values close to 60 where the line starts decreasing, although actual data don&rsquo;t show that.</p>
<p>Finally, on the bottom right plot, you can see the perfect fit: six points and the polynomial line of the degree 5 (or higher) yield 𝑅² = 1.
Each actual response equals its corresponding prediction. </p>
<p>In some situations, this might be exactly what you&rsquo;re looking for. In many cases, however, this is an overfitted model. It is likely to have poor behavior with unseen data, especially with the inputs larger than 50.</p>
<p>For example, it assumes, without any evidence, that there is a significant drop in responses for 𝑥 &gt; 50 and that 𝑦 reaches zero for 𝑥 near 60. Such behavior is the consequence of excessive effort to learn and fit the existing data.</p>
<p>There are a lot of resources where you can find more information about regression in general and linear regression in particular. The <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression analysis page on Wikipedia</a>, <a href="https://en.wikipedia.org/wiki/Linear_regression">Wikipedia&rsquo;s linear regression article</a>, as well as <a href="https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/introduction-to-trend-lines/a/linear-regression-review">Khan Academy&rsquo;s linear regression article</a> are good starting points.</p>
</section></section><section class="section2" id="implementing-linear-regression-in-python"><h2>Implementing Linear Regression in Python<a class="headerlink" href="#implementing-linear-regression-in-python" title="Permanent link"></a></h2>
<p>It&rsquo;s time to start implementing linear regression in Python. Basically, all you should do is apply the proper packages and their functions and classes.</p>
<section class="section3" id="python-packages-for-linear-regression"><h3>Python Packages for Linear Regression<a class="headerlink" href="#python-packages-for-linear-regression" title="Permanent link"></a></h3>
<p>The package <strong>NumPy</strong> is a fundamental Python scientific package that allows many high-performance operations on single- and multi-dimensional arrays. It also offers many mathematical routines. Of course, it&rsquo;s open source.</p>
<p>If you&rsquo;re not familiar with NumPy, you can use the official <a href="https://docs.scipy.org/doc/numpy/user/index.html">NumPy User Guide</a> and read <a href="https://realpython.com/numpy-array-programming/">Look Ma, No For-Loops: Array Programming With NumPy</a>. In addition, <a href="https://realpython.com/numpy-tensorflow-performance/">Pure Python vs NumPy vs TensorFlow Performance Comparison</a> can give you a pretty good idea on the performance gains you can achieve when applying NumPy.</p>
<p>The package <strong>scikit-learn</strong> is a widely used Python library for machine learning, built on top of NumPy and some other packages. It provides the means for preprocessing data, reducing dimensionality, implementing regression, classification, clustering, and more. Like NumPy, scikit-learn is also open source.</p>
<p>You can check the page <a href="https://scikit-learn.org/stable/modules/linear_model.html">Generalized Linear Models</a> on the <a href="https://scikit-learn.org/stable/">scikit-learn web site</a> to learn more about linear models and get deeper insight into how this package works.</p>
<p>If you want to implement linear regression and need the functionality beyond the scope of scikit-learn, you should consider <strong><code>statsmodels</code></strong>. It&rsquo;s a powerful Python package for the estimation of statistical models, performing tests, and more. It&rsquo;s open source as well.</p>
<p>You can find more information on <code>statsmodels</code> on <a href="https://www.statsmodels.org/stable/index.html">its official web site</a>.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section><section class="section3" id="simple-linear-regression-with-scikit-learn"><h3>Simple Linear Regression With scikit-learn<a class="headerlink" href="#simple-linear-regression-with-scikit-learn" title="Permanent link"></a></h3>
<p>Let&rsquo;s start with the simplest case, which is simple linear regression.</p>
<p>There are five basic steps when you&rsquo;re implementing linear regression:</p>
<ol>
<li>Import the packages and classes you need.</li>
<li>Provide data to work with and eventually do appropriate transformations.</li>
<li>Create a regression model and fit it with existing data.</li>
<li>Check the results of model fitting to know whether the model is satisfactory.</li>
<li>Apply the model for predictions.</li>
</ol>
<p>These steps are more or less general for most of the regression approaches and implementations.</p>
<p><strong>Step 1: Import packages and classes</strong></p>
<p>The first step is to import the package <code>numpy</code> and the class <code>LinearRegression</code> from <code>sklearn.linear_model</code>:</p>
<div class="highlight python"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</code></pre></div>
<p>Now, you have all the functionalities you need to implement linear regression.</p>
<p>The fundamental data type of NumPy is the array type called <code>numpy.ndarray</code>. The rest of this article uses the term <strong>array</strong> to refer to instances of the type <code>numpy.ndarray</code>.</p>
<p>The class <code>sklearn.linear_model.LinearRegression</code> will be used to perform linear and polynomial regression and make predictions accordingly.</p>
<p><strong>Step 2: Provide data</strong></p>
<p>The second step is defining data to work with. The inputs (regressors, 𝑥) and output (predictor, 𝑦) should be arrays (the instances of the class <code>numpy.ndarray</code>) or similar objects. This is the simplest way of providing data for regression:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">55</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">38</span><span class="p">])</span>
</code></pre></div>
<p>Now, you have two arrays: the input <code>x</code> and output <code>y</code>. You should call <code>.reshape()</code> on <code>x</code> because this array is required to be <strong>two-dimensional</strong>, or to be more precise, to have <strong>one column and as many rows as necessary</strong>. That&rsquo;s exactly what the argument <code>(-1, 1)</code> of <code>.reshape()</code> specifies. </p>
<p>This is how <code>x</code> and <code>y</code> look now:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[ 5]</span>
<span class="go"> [15]</span>
<span class="go"> [25]</span>
<span class="go"> [35]</span>
<span class="go"> [45]</span>
<span class="go"> [55]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[ 5 20 14 32 22 38]</span>
</code></pre></div>
<p>As you can see, <code>x</code> has two dimensions, and <code>x.shape</code> is <code>(6, 1)</code>, while <code>y</code> has a single dimension, and <code>y.shape</code> is <code>(6,)</code>.</p>
<p><strong>Step 3: Create a model and fit it</strong></p>
<p>The next step is to create a linear regression model and fit it using the existing data.</p>
<p>Let&rsquo;s create an instance of the class <code>LinearRegression</code>, which will represent the regression model:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</code></pre></div>
<p>This statement creates the variable <code>model</code> as the instance of <code>LinearRegression</code>. You can provide several optional parameters to <code>LinearRegression</code>:</p>
<ul>
<li><strong><code>fit_intercept</code></strong> is a <a href="https://realpython.com/python-boolean/">Boolean</a> (<code>True</code> by default) that decides whether to calculate the intercept 𝑏₀ (<code>True</code>) or consider it equal to zero (<code>False</code>).</li>
<li><strong><code>normalize</code></strong> is a Boolean (<code>False</code> by default) that decides whether to normalize the input variables (<code>True</code>) or not (<code>False</code>).</li>
<li><strong><code>copy_X</code></strong> is a Boolean (<code>True</code> by default) that decides whether to copy (<code>True</code>) or overwrite the input variables (<code>False</code>).</li>
<li><strong><code>n_jobs</code></strong> is an integer or <code>None</code> (default) and represents the number of jobs used in parallel computation. <code>None</code> usually means one job and <code>-1</code> to use all processors.</li>
</ul>
<p>This example uses the default values of all parameters.</p>
<p>It&rsquo;s time to start using the model. First, you need to call <code>.fit()</code> on <code>model</code>:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>With <code>.fit()</code>, you calculate the optimal values of the weights 𝑏₀ and 𝑏₁, using the existing input and output (<code>x</code> and <code>y</code>) as the arguments. In other words, <code>.fit()</code> <strong>fits the model</strong>. It returns <code>self</code>, which is the variable <code>model</code> itself. That&rsquo;s why you can replace the last two statements with this one:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>This statement does the same thing as the previous two. It&rsquo;s just shorter.</p>
<p><strong>Step 4: Get results</strong></p>
<p>Once you have your model fitted, you can get the results to check whether the model works satisfactorily and interpret it.</p>
<p>You can obtain the coefficient of determination (𝑅²) with <code>.score()</code> called on <code>model</code>:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">r_sq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">r_sq</span><span class="p">)</span>
<span class="go">coefficient of determination: 0.715875613747954</span>
</code></pre></div>
<p>When you&rsquo;re applying <code>.score()</code>, the arguments are also the predictor <code>x</code> and regressor <code>y</code>, and the return value is 𝑅².</p>
<p>The attributes of <code>model</code> are <code>.intercept_</code>, which represents the coefficient, 𝑏₀ and <code>.coef_</code>, which represents 𝑏₁:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">intercept: 5.633333333333329</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">slope: [0.54]</span>
</code></pre></div>
<p>The code above illustrates how to get 𝑏₀ and 𝑏₁. You can notice that <code>.intercept_</code> is a scalar, while <code>.coef_</code> is an array.</p>
<p>The value 𝑏₀ = 5.63 (approximately) illustrates that your model predicts the response 5.63 when 𝑥 is zero. The value 𝑏₁ = 0.54 means that the predicted response rises by 0.54 when 𝑥 is increased by one.</p>
<p>You should notice that you can provide <code>y</code> as a two-dimensional array as well. In this case, you&rsquo;ll get a similar result. This is how it might look:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">new_model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept:&#39;</span><span class="p">,</span> <span class="n">new_model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">intercept: [5.63333333]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope:&#39;</span><span class="p">,</span> <span class="n">new_model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">slope: [[0.54]]</span>
</code></pre></div>
<p>As you can see, this example is very similar to the previous one, but in this case, <code>.intercept_</code> is a one-dimensional array with the single element 𝑏₀, and <code>.coef_</code> is a two-dimensional array with the single element 𝑏₁.</p>
<p><strong>Step 5: Predict response</strong></p>
<p>Once there is a satisfactory model, you can use it for predictions with either existing or new data.</p>
<p>To obtain the predicted response, use <code>.predict()</code>:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]</span>
</code></pre></div>
<p>When applying <code>.predict()</code>, you pass the regressor as the argument and get the corresponding predicted response.</p>
<p>This is a nearly identical way to predict the response:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span> <span class="o">*</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[[ 8.33333333]</span>
<span class="go"> [13.73333333]</span>
<span class="go"> [19.13333333]</span>
<span class="go"> [24.53333333]</span>
<span class="go"> [29.93333333]</span>
<span class="go"> [35.33333333]]</span>
</code></pre></div>
<p>In this case, you multiply each element of <code>x</code> with <code>model.coef_</code> and add <code>model.intercept_</code> to the product.</p>
<p>The output here differs from the previous example only in dimensions. The predicted response is now a two-dimensional array, while in the previous case, it had one dimension.</p>
<p>If you reduce the number of dimensions of <code>x</code> to one, these two approaches will yield the same result. You can do this by replacing <code>x</code> with <code>x.reshape(-1)</code>, <code>x.flatten()</code>, or <code>x.ravel()</code> when multiplying it with <code>model.coef_</code>.</p>
<p>In practice, regression models are often applied for forecasts. This means that you can use fitted models to calculate the outputs based on some other, new inputs:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">x_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
<span class="go">[[0]</span>
<span class="go"> [1]</span>
<span class="go"> [2]</span>
<span class="go"> [3]</span>
<span class="go"> [4]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_new</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y_new</span><span class="p">)</span>
<span class="go">[5.63333333 6.17333333 6.71333333 7.25333333 7.79333333]</span>
</code></pre></div>
<p>Here <code>.predict()</code> is applied to the new regressor <code>x_new</code> and yields the response <code>y_new</code>. This example conveniently uses <a href="https://realpython.com/how-to-use-numpy-arange/"><code>arange()</code></a> from <code>numpy</code> to generate an array with the elements from 0 (inclusive) to 5 (exclusive), that is <code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>, and <code>4</code>.</p>
<p>You can find more information about <code>LinearRegression</code> on <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">the official documentation page</a>.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section><section class="section3" id="multiple-linear-regression-with-scikit-learn"><h3>Multiple Linear Regression With scikit-learn<a class="headerlink" href="#multiple-linear-regression-with-scikit-learn" title="Permanent link"></a></h3>
<p>You can implement multiple linear regression following the same steps as you would for simple regression.</p>
<p><strong>Steps 1 and 2: Import packages and classes, and provide data</strong></p>
<p>First, you import <code>numpy</code> and <code>sklearn.linear_model.LinearRegression</code> and provide known inputs and output:</p>
<div class="highlight python"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">45</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">55</span><span class="p">,</span> <span class="mi">34</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">35</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">43</span><span class="p">]</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>That&rsquo;s a simple way to define the input <code>x</code> and output <code>y</code>. You can print <code>x</code> and <code>y</code> to see how they look now:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[ 0  1]</span>
<span class="go"> [ 5  1]</span>
<span class="go"> [15  2]</span>
<span class="go"> [25  5]</span>
<span class="go"> [35 11]</span>
<span class="go"> [45 15]</span>
<span class="go"> [55 34]</span>
<span class="go"> [60 35]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[ 4  5 20 14 32 22 38 43]</span>
</code></pre></div>
<p>In multiple linear regression, <code>x</code> is a two-dimensional array with at least two columns, while <code>y</code> is usually a one-dimensional array. This is a simple example of multiple linear regression, and <code>x</code> has exactly two columns.</p>
<p><strong>Step 3: Create a model and fit it</strong></p>
<p>The next step is to create the regression model as an instance of <code>LinearRegression</code> and fit it with <code>.fit()</code>:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>The result of this statement is the variable <code>model</code> referring to the object of type <code>LinearRegression</code>. It represents the regression model fitted with existing data.</p>
<p><strong>Step 4: Get results</strong></p>
<p>You can obtain the properties of the model the same way as in the case of simple linear regression:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">r_sq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">r_sq</span><span class="p">)</span>
<span class="go">coefficient of determination: 0.8615939258756776</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">intercept: 5.52257927519819</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;slope:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">slope: [0.44706965 0.25502548]</span>
</code></pre></div>
<p>You obtain the value of 𝑅² using <code>.score()</code> and the values of the estimators of regression coefficients with <code>.intercept_</code> and <code>.coef_</code>. Again, <code>.intercept_</code> holds the bias 𝑏₀, while now <code>.coef_</code> is an array containing 𝑏₁ and 𝑏₂ respectively.</p>
<p>In this example, the intercept is approximately 5.52, and this is the value of the predicted response when 𝑥₁ = 𝑥₂ = 0. The increase of 𝑥₁ by 1 yields the rise of the predicted response by 0.45. Similarly, when 𝑥₂ grows by 1, the response rises by 0.26.</p>
<p><strong>Step 5: Predict response</strong></p>
<p>Predictions also work the same way as in the case of simple linear regression:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957</span>
<span class="go"> 38.78227633 41.27265006]</span>
</code></pre></div>
<p>The predicted response is obtained with <code>.predict()</code>, which is very similar to the following:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957</span>
<span class="go"> 38.78227633 41.27265006]</span>
</code></pre></div>
<p>You can predict the output values by multiplying each column of the input with the appropriate weight, summing the results and adding the intercept to the sum.</p>
<p>You can apply this model to new data as well:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">x_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
<span class="go">[[0 1]</span>
<span class="go"> [2 3]</span>
<span class="go"> [4 5]</span>
<span class="go"> [6 7]</span>
<span class="go"> [8 9]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_new</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y_new</span><span class="p">)</span>
<span class="go">[ 5.77760476  7.18179502  8.58598528  9.99017554 11.3943658 ]</span>
</code></pre></div>
<p>That&rsquo;s the prediction using a linear regression model.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section><section class="section3" id="polynomial-regression-with-scikit-learn"><h3>Polynomial Regression With scikit-learn<a class="headerlink" href="#polynomial-regression-with-scikit-learn" title="Permanent link"></a></h3>
<p>Implementing polynomial regression with scikit-learn is very similar to linear regression. There is only one extra step: you need to transform the array of inputs to include non-linear terms such as 𝑥².</p>
<p><strong>Step 1: Import packages and classes</strong></p>
<p>In addition to <code>numpy</code> and <code>sklearn.linear_model.LinearRegression</code>, you should also import the class <code>PolynomialFeatures</code> from <code>sklearn.preprocessing</code>:</p>
<div class="highlight python"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
</code></pre></div>
<p>The import is now done, and you have everything you need to work with.</p>
<p><strong>Step 2a: Provide data</strong></p>
<p>This step defines the input and output and is the same as in the case of linear regression:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">55</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">15</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
</code></pre></div>
<p>Now you have the input and output in a suitable format. Keep in mind that you need the input to be a <strong>two-dimensional array</strong>. That&rsquo;s why <code>.reshape()</code> is used.</p>
<p><strong>Step 2b: Transform input data</strong></p>
<p>This is the <strong>new step</strong> you need to implement for polynomial regression!</p>
<p>As you&rsquo;ve seen earlier, you need to include 𝑥² (and perhaps other terms) as additional features when implementing polynomial regression. For that reason, you should transform the input array <code>x</code> to contain the additional column(s) with the values of 𝑥² (and eventually more features).</p>
<p>It&rsquo;s possible to transform the input array in several ways (like using <code>insert()</code> from <code>numpy</code>), but the class <code>PolynomialFeatures</code> is very convenient for this purpose. Let&rsquo;s create an instance of this class:</p>
<div class="highlight python"><pre><span></span><code><span class="n">transformer</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>The variable <code>transformer</code> refers to an instance of <code>PolynomialFeatures</code> which you can use to transform the input <code>x</code>.</p>
<p>You can provide several optional parameters to <code>PolynomialFeatures</code>:</p>
<ul>
<li><strong><code>degree</code></strong> is an integer (<code>2</code> by default) that represents the degree of the polynomial regression function.</li>
<li><strong><code>interaction_only</code></strong> is a Boolean (<code>False</code> by default) that decides whether to include only interaction features (<code>True</code>) or all features (<code>False</code>).</li>
<li><strong><code>include_bias</code></strong> is a Boolean (<code>True</code> by default) that decides whether to include the bias (intercept) column of ones (<code>True</code>) or not (<code>False</code>).</li>
</ul>
<p>This example uses the default values of all parameters, but you&rsquo;ll sometimes want to experiment with the degree of the function, and it can be beneficial to provide this argument anyway.</p>
<p>Before applying <code>transformer</code>, you need to fit it with <code>.fit()</code>:</p>
<div class="highlight python"><pre><span></span><code><span class="n">transformer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>Once <code>transformer</code> is fitted, it&rsquo;s ready to create a new, modified input. You apply <code>.transform()</code> to do that:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x_</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>That&rsquo;s the transformation of the input array with <code>.transform()</code>. It takes the input array as the argument and returns the modified array.</p>
<p>You can also use <code>.fit_transform()</code> to replace the three previous statements with only one:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>That&rsquo;s fitting and transforming the input array in one statement with <code>.fit_transform()</code>. It also takes the input array and effectively does the same thing as <code>.fit()</code> and <code>.transform()</code> called in that order. It also returns the modified array. This is how the new input array looks:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
<span class="go">[[   5.   25.]</span>
<span class="go"> [  15.  225.]</span>
<span class="go"> [  25.  625.]</span>
<span class="go"> [  35. 1225.]</span>
<span class="go"> [  45. 2025.]</span>
<span class="go"> [  55. 3025.]]</span>
</code></pre></div>
<p>The modified input array contains two columns: one with the original inputs and the other with their squares.</p>
<p>You can find more information about <code>PolynomialFeatures</code> on <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">the official documentation page</a>.</p>
<p><strong>Step 3: Create a model and fit it</strong></p>
<p>This step is also the same as in the case of linear regression. You create and fit the model:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>The regression model is now created and fitted. It&rsquo;s ready for application.</p>
<p>You should keep in mind that the first argument of <code>.fit()</code> is the <em>modified input array</em> <code>x_</code> and not the original <code>x</code>.</p>
<p><strong>Step 4: Get results</strong></p>
<p>You can obtain the properties of the model the same way as in the case of linear regression:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">r_sq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">r_sq</span><span class="p">)</span>
<span class="go">coefficient of determination: 0.8908516262498564</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">intercept: 21.372321428571425</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficients:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">coefficients: [-1.32357143  0.02839286]</span>
</code></pre></div>
<p>Again, <code>.score()</code> returns 𝑅². Its first argument is also the modified input <code>x_</code>, not <code>x</code>. The values of the weights are associated to <code>.intercept_</code> and <code>.coef_</code>: <code>.intercept_</code> represents 𝑏₀, while <code>.coef_</code> references the array that contains 𝑏₁ and 𝑏₂ respectively.</p>
<p>You can obtain a very similar result with different transformation and regression arguments:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>If you call <code>PolynomialFeatures</code> with the default parameter <code>include_bias=True</code> (or if you just omit it), you&rsquo;ll obtain the new input array <code>x_</code> with the additional leftmost column containing only ones. This column corresponds to the intercept. This is how the modified input array looks in this case:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
<span class="go">[[1.000e+00 5.000e+00 2.500e+01]</span>
<span class="go"> [1.000e+00 1.500e+01 2.250e+02]</span>
<span class="go"> [1.000e+00 2.500e+01 6.250e+02]</span>
<span class="go"> [1.000e+00 3.500e+01 1.225e+03]</span>
<span class="go"> [1.000e+00 4.500e+01 2.025e+03]</span>
<span class="go"> [1.000e+00 5.500e+01 3.025e+03]]</span>
</code></pre></div>
<p>The first column of <code>x_</code> contains ones, the second has the values of <code>x</code>, while the third holds the squares of <code>x</code>.</p>
<p>The intercept is already included with the leftmost column of ones, and you don&rsquo;t need to include it again when creating the instance of <code>LinearRegression</code>. Thus, you can provide <code>fit_intercept=False</code>. This is how the next statement looks:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>The variable <code>model</code> again corresponds to the new input array <code>x_</code>. Therefore <code>x_</code> should be passed as the first argument instead of <code>x</code>.</p>
<p>This approach yields the following results, which are similar to the previous case:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">r_sq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">r_sq</span><span class="p">)</span>
<span class="go">coefficient of determination: 0.8908516262498565</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="go">intercept: 0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficients:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="go">coefficients: [21.37232143 -1.32357143  0.02839286]</span>
</code></pre></div>
<p>You see that now <code>.intercept_</code> is zero, but <code>.coef_</code> actually contains 𝑏₀ as its first element. Everything else is the same.</p>
<p><strong>Step 5: Predict response</strong></p>
<p>If you want to get the predicted response, just use <code>.predict()</code>, but remember that the argument should be the modified input <code>x_</code> instead of the old <code>x</code>:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[15.46428571  7.90714286  6.02857143  9.82857143 19.30714286 34.46428571]</span>
</code></pre></div>
<p>As you can see, the prediction works almost the same way as in the case of linear regression. It just requires the modified input instead of the original.</p>
<p>You can apply the identical procedure if you have <strong>several input variables</strong>. You&rsquo;ll have an input array with more than one column, but everything else is the same. Here is an example:</p>
<div class="highlight python"><pre><span></span><code><span class="c1"># Step 1: Import packages</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="c1"># Step 2a: Provide data</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">45</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">55</span><span class="p">,</span> <span class="mi">34</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">35</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">43</span><span class="p">]</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Step 2b: Transform input data</span>
<span class="n">x_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Step 3: Create a model and fit it</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Step 4: Get results</span>
<span class="n">r_sq</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">intercept</span><span class="p">,</span> <span class="n">coefficients</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>

<span class="c1"># Step 5: Predict</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
</code></pre></div>
<p>This regression example yields the following results and predictions:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">r_sq</span><span class="p">)</span>
<span class="go">coefficient of determination: 0.9453701449127822</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;intercept:&#39;</span><span class="p">,</span> <span class="n">intercept</span><span class="p">)</span>
<span class="go">intercept: 0.8430556452395734</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficients:&#39;</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">coefficients:</span>
<span class="go">[ 2.44828275  0.16160353 -0.15259677  0.47928683 -0.4641851 ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[ 0.54047408 11.36340283 16.07809622 15.79139    29.73858619 23.50834636</span>
<span class="go"> 39.05631386 41.92339046]</span>
</code></pre></div>
<p>In this case, there are six regression coefficients (including the intercept), as shown in the estimated regression function 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂ + 𝑏₃𝑥₁² + 𝑏₄𝑥₁𝑥₂ + 𝑏₅𝑥₂².</p>
<p>You can also notice that polynomial regression yielded a higher coefficient of determination than multiple linear regression for the same problem. At first, you could think that obtaining such a large 𝑅² is an excellent result. It might be.</p>
<p>However, in real-world situations, having a complex model and 𝑅² very close to 1 might also be a sign of overfitting. To check the performance of a model, you should test it with new data, that is with observations not used to fit (train) the model. To learn how to split your dataset into the training and test subsets, check out <a href="https://realpython.com/train-test-split-python-data/">Split Your Dataset With scikit-learn&rsquo;s train_test_split()</a>.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section><section class="section3" id="advanced-linear-regression-with-statsmodels"><h3>Advanced Linear Regression With <code>statsmodels</code><a class="headerlink" href="#advanced-linear-regression-with-statsmodels" title="Permanent link"></a></h3>
<p>You can implement linear regression in Python relatively easily by using the package <code>statsmodels</code> as well. Typically, this is desirable when there is a need for more detailed results.</p>
<p>The procedure is similar to that of scikit-learn.</p>
<p><strong>Step 1: Import packages</strong></p>
<p>First you need to do some imports. In addition to <code>numpy</code>, you need to import <code>statsmodels.api</code>:</p>
<div class="highlight python"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
</code></pre></div>
<p>Now you have the packages you need.</p>
<p><strong>Step 2: Provide data and transform inputs</strong></p>
<p>You can provide the inputs and outputs the same way as you did when you were using scikit-learn:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">45</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">55</span><span class="p">,</span> <span class="mi">34</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">35</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">43</span><span class="p">]</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>The input and output arrays are created, but the job is not done yet.</p>
<p>You need to add the column of ones to the inputs if you want <code>statsmodels</code> to calculate the intercept 𝑏₀. It doesn&rsquo;t takes 𝑏₀ into account by default. This is just one function call:</p>
<div class="highlight python"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>That&rsquo;s how you add the column of ones to <code>x</code> with <code>add_constant()</code>. It takes the input array <code>x</code> as an argument and returns a new array with the column of ones inserted at the beginning. This is how <code>x</code> and <code>y</code> look now:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[ 1.  0.  1.]</span>
<span class="go"> [ 1.  5.  1.]</span>
<span class="go"> [ 1. 15.  2.]</span>
<span class="go"> [ 1. 25.  5.]</span>
<span class="go"> [ 1. 35. 11.]</span>
<span class="go"> [ 1. 45. 15.]</span>
<span class="go"> [ 1. 55. 34.]</span>
<span class="go"> [ 1. 60. 35.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[ 4  5 20 14 32 22 38 43]</span>
</code></pre></div>
<p>You can see that the modified <code>x</code> has three columns: the first column of ones (corresponding to 𝑏₀ and replacing the intercept) as well as two columns of the original features.</p>
<p><strong>Step 3: Create a model and fit it</strong></p>
<p>The regression model based on ordinary least squares is an instance of the class <code>statsmodels.regression.linear_model.OLS</code>. This is how you can obtain one:</p>
<div class="highlight python"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>You should be careful here! Please, notice that the first argument is the output, followed with the input. There are several more optional parameters.</p>
<p>To find more information about this class, please visit <a href="https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html">the official documentation page</a>.</p>
<p>Once your model is created, you can apply <code>.fit()</code> on it:</p>
<div class="highlight python"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</code></pre></div>
<p>By calling <code>.fit()</code>, you obtain the variable <code>results</code>, which is an instance of the class <code>statsmodels.regression.linear_model.RegressionResultsWrapper</code>. This object holds a lot of information about the regression model.</p>
<p><strong>Step 4: Get results</strong></p>
<p>The variable <code>results</code> refers to the object that contains detailed information about the results of linear regression. Explaining them is far beyond the scope of this article, but you&rsquo;ll learn here how to extract them.</p>
<p>You can call <code>.summary()</code> to get the table with the results of linear regression:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="go">OLS Regression Results                            </span>
<span class="go">==============================================================================</span>
<span class="go">Dep. Variable:                      y   R-squared:                       0.862</span>
<span class="go">Model:                            OLS   Adj. R-squared:                  0.806</span>
<span class="go">Method:                 Least Squares   F-statistic:                     15.56</span>
<span class="go">Date:                Sun, 17 Feb 2019   Prob (F-statistic):            0.00713</span>
<span class="go">Time:                        19:15:07   Log-Likelihood:                -24.316</span>
<span class="go">No. Observations:                   8   AIC:                             54.63</span>
<span class="go">Df Residuals:                       5   BIC:                             54.87</span>
<span class="go">Df Model:                           2                                         </span>
<span class="go">Covariance Type:            nonrobust                                         </span>
<span class="go">==============================================================================</span>
<span class="go">coef    std err          t      P&gt;|t|      [0.025      0.975]</span>
<span class="go">------------------------------------------------------------------------------</span>
<span class="go">const          5.5226      4.431      1.246      0.268      -5.867      16.912</span>
<span class="go">x1             0.4471      0.285      1.567      0.178      -0.286       1.180</span>
<span class="go">x2             0.2550      0.453      0.563      0.598      -0.910       1.420</span>
<span class="go">==============================================================================</span>
<span class="go">Omnibus:                        0.561   Durbin-Watson:                   3.268</span>
<span class="go">Prob(Omnibus):                  0.755   Jarque-Bera (JB):                0.534</span>
<span class="go">Skew:                           0.380   Prob(JB):                        0.766</span>
<span class="go">Kurtosis:                       1.987   Cond. No.                         80.1</span>
<span class="go">==============================================================================</span>

<span class="go">Warnings:</span>
<span class="go">[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</span>
</code></pre></div>
<p>This table is very comprehensive. You can find many statistical values associated with linear regression including 𝑅², 𝑏₀, 𝑏₁, and 𝑏₂.</p>
<p>In this particular case, you might obtain the warning related to <code>kurtosistest</code>. This is due to the small number of observations provided.</p>
<p>You can extract any of the values from the table above. Here&rsquo;s an example:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
<span class="go">coefficient of determination: 0.8615939258756777</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;adjusted coefficient of determination:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared_adj</span><span class="p">)</span>
<span class="go">adjusted coefficient of determination: 0.8062314962259488</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;regression coefficients:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">regression coefficients: [5.52257928 0.44706965 0.25502548]</span>
</code></pre></div>
<p>That&rsquo;s how you obtain some of the results of linear regression:</p>
<ol>
<li><strong><code>.rsquared</code></strong> holds 𝑅².</li>
<li><strong><code>.rsquared_adj</code></strong> represents adjusted 𝑅² (𝑅² corrected according to the number of input features).</li>
<li><strong><code>.params</code></strong> refers the array with 𝑏₀, 𝑏₁, and 𝑏₂ respectively.</li>
</ol>
<p>You can also notice that these results are identical to those obtained with scikit-learn for the same problem.</p>
<p>To find more information about the results of linear regression, please visit <a href="https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.RegressionResults.html">the official documentation page</a>.</p>
<p><strong>Step 5: Predict response</strong></p>
<p>You can obtain the predicted response on the input values used for creating the model using <code>.fittedvalues</code> or <code>.predict()</code> with the input array as the argument:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957</span>
<span class="go"> 38.78227633 41.27265006]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted response:&#39;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="go">predicted response:</span>
<span class="go">[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957</span>
<span class="go"> 38.78227633 41.27265006]</span>
</code></pre></div>
<p>This is the predicted response for known inputs. If you want predictions with new regressors, you can also apply <code>.predict()</code> with new data as the argument:</p>
<div class="highlight python repl"><span class="repl-toggle" title="Toggle REPL prompts and output">&gt;&gt;&gt;</span><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">x_new</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
<span class="go">[[1. 0. 1.]</span>
<span class="go"> [1. 2. 3.]</span>
<span class="go"> [1. 4. 5.]</span>
<span class="go"> [1. 6. 7.]</span>
<span class="go"> [1. 8. 9.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_new</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y_new</span><span class="p">)</span>
<span class="go">[ 5.77760476  7.18179502  8.58598528  9.99017554 11.3943658 ]</span>
</code></pre></div>
<p>You can notice that the predicted results are the same as those obtained with scikit-learn for the same problem.</p>
<div><div class="rounded border border-light" style="display:block;position:relative;"><div style="display:block;width:100%;padding-top:12.5%;"></div><div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div></div><a class="small text-muted" href="/account/join/" rel="nofollow"><i aria-hidden="true" class="fa fa-info-circle"> </i> Remove ads</a></div></section></section><section class="section2" id="beyond-linear-regression"><h2>Beyond Linear Regression<a class="headerlink" href="#beyond-linear-regression" title="Permanent link"></a></h2>
<p>Linear regression is sometimes not appropriate, especially for non-linear models of high complexity.</p>
<p>Fortunately, there are other regression techniques suitable for the cases where linear regression doesn&rsquo;t work well. Some of them are support vector machines, decision trees, random forest, and neural networks.</p>
<p>There are numerous Python libraries for regression using these techniques. Most of them are free and open-source. That&rsquo;s one of the reasons why Python is among the main programming languages for machine learning.</p>
<p>The package scikit-learn provides the means for using other regression techniques in a very similar way to what you&rsquo;ve seen. It contains the classes for support vector machines, decision trees, random forest, and more, with the methods <code>.fit()</code>, <code>.predict()</code>, <code>.score()</code> and so on.</p>
</section><section class="section2" id="conclusion"><h2>Conclusion<a class="headerlink" href="#conclusion" title="Permanent link"></a></h2>
<p>You now know what linear regression is and how you can implement it with Python and three open-source packages: NumPy, scikit-learn, and <code>statsmodels</code>.</p>
<p>You use NumPy for handling arrays.</p>
<p>Linear regression is implemented with the following:</p>
<ul>
<li><strong>scikit-learn</strong> if you don&rsquo;t need detailed results and want to use the approach consistent with other regression techniques</li>
<li><strong>statsmodels</strong> if you need the advanced statistical parameters of a model</li>
</ul>
<p>Both approaches are worth learning how to use and exploring further. The links in this article can be very useful for that.</p>
<p>When performing linear regression in Python, you can follow these steps:</p>
<ol>
<li>Import the packages and classes you need</li>
<li>Provide data to work with and eventually do appropriate transformations</li>
<li>Create a regression model and fit it with existing data</li>
<li>Check the results of model fitting to know whether the model is satisfactory</li>
<li>Apply the model for predictions</li>
</ol>
<p>If you have questions or comments, please put them in the comment section below.</p>
</section>
<div class="text-center my-3">
<div class="jsCompletionStatusWidget btn-group mb-0">
<button title="Click to mark as completed" class="jsBtnCompletion btn btn-secondary border-right " style="border-top-right-radius: 0; border-bottom-right-radius: 0;" disabled>Mark as Completed</button>
<button title="Add bookmark" class="jsBtnBookmark btn btn-secondary border-left" disabled><i class="fa fa-fw fa-bookmark-o"></i></button>
</div>
</div>
</div>
<div class="card mt-4 mb-4 bg-secondary">
<p class="card-header h3 text-center bg-light">🐍 Python Tricks 💌</p>
<div class="card-body">
<div class="container">
<div class="row">
<div class="col-xs-12 col-sm-7">
<p>Get a short &amp; sweet <strong>Python Trick</strong> delivered to your inbox every couple of days. No spam ever. Unsubscribe any time. Curated by the Real Python team.</p>
</div>
<div class="col-xs-12 col-sm-5">
<img class="img-fluid rounded mb-3" src="https://cdn.realpython.com/static/pytrick-dict-merge.4201a0125a5e.png" width="738" height="490" alt="Python Tricks Dictionary Merge">
</div>
</div>
<div class="row mb-3">
<form class="col-12" action="/optins/process/" method="post">
<input type="hidden" name="csrfmiddlewaretoken" value="6VxoFY4jQ9ftCnk0Kv5ORe4tyyfmrrnxc0cBgxghbEaDMgZIThxYhj3pOtkgEZRm">
<input type="hidden" name="slug" value="static-python-tricks-footer">
<div class="form-group">
<input name="email" type="email" class="form-control form-control-lg" placeholder="Email Address" required>
</div>
<button name="submit" type="submit" class="btn btn-primary btn-lg btn-block">Send Me Python Tricks »</button>
</form>
</div>
</div>
</div>
</div>
<div class="card mt-3" id="author">
<p class="card-header h3">About <strong>Mirko Stojiljković</strong></p>
 <div class="card-body">
<div class="container p-0">
<div class="row">
<div class="col-12 col-md-3 align-self-center">
<a href="/team/mstojiljkovic/"><img loading="lazy" src="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=240&amp;h=240&amp;mode=crop&amp;sig=3952dbe00532973b3680e177512373bbdcdbbe75" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=60&amp;h=60&amp;mode=crop&amp;sig=b538cfe117b64a6189f297e361f4aea7b3bf4298 60w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=120&amp;h=120&amp;mode=crop&amp;sig=441f902e060a34910f8c426ebb02b5560078d98f 120w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=240&amp;h=240&amp;mode=crop&amp;sig=3952dbe00532973b3680e177512373bbdcdbbe75 240w" sizes="25vw" width="240" height="240" class="d-block d-md-none rounded-circle img-fluid w-33 mb-0 mx-auto" alt="Mirko Stojiljković"></a>
<a href="/team/mstojiljkovic/"><img loading="lazy" src="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=240&amp;h=240&amp;mode=crop&amp;sig=3952dbe00532973b3680e177512373bbdcdbbe75" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=60&amp;h=60&amp;mode=crop&amp;sig=b538cfe117b64a6189f297e361f4aea7b3bf4298 60w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=120&amp;h=120&amp;mode=crop&amp;sig=441f902e060a34910f8c426ebb02b5560078d98f 120w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/ms.fdcd0bdc2f4a.png&amp;w=240&amp;h=240&amp;mode=crop&amp;sig=3952dbe00532973b3680e177512373bbdcdbbe75 240w" sizes="25vw" width="240" height="240" class="d-none d-md-block rounded-circle img-fluid w-100 mb-0" alt="Mirko Stojiljković"></a>
</div>
<div class="col mt-3">
<p>Mirko has a Ph.D. in Mechanical Engineering and works as a university professor. He is a Pythonista who applies hybrid optimization and machine learning methods to support decision making in the energy sector.</p>
<a href="/team/mstojiljkovic/" class="card-link">» More about Mirko</a>
</div>
</div>
</div>
</div>
<hr class="my-0">
<div class="card-body pb-0">
<div class="container">
<div class="row">
<p><em>Each tutorial at Real Python is created by a team of developers so that it meets our high quality standards. The team members who worked on this tutorial are:</em></p>
</div>
<div class="row align-items-center w-100 mx-auto">
<div class="col-4 col-sm-2 align-self-center">
<a href="/team/asantos/"><img loading="lazy" src="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/asantos-avatar.888c78fffab3.jpg&amp;w=700&amp;h=700&amp;mode=crop&amp;sig=be17609cd7f6a4cd249ff61e186b3ad1aece949c" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/asantos-avatar.888c78fffab3.jpg&amp;w=175&amp;h=175&amp;mode=crop&amp;sig=30253487c673fd67bb45ea6bef95b3c57e115e46 175w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/asantos-avatar.888c78fffab3.jpg&amp;w=350&amp;h=350&amp;mode=crop&amp;sig=a43bd9ea30a6f61a4fc2451ab9abfc6faec8a2c0 350w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/asantos-avatar.888c78fffab3.jpg&amp;w=700&amp;h=700&amp;mode=crop&amp;sig=be17609cd7f6a4cd249ff61e186b3ad1aece949c 700w" sizes="10vw" width="240" height="240" class="rounded-circle img-fluid w-100" alt="Aldren Santos"></a>
</div>
<div class="col pl-0 d-none d-sm-block">
<a href="/team/asantos/" class="card-link small"><p>Aldren</p></a>
</div>
<div class="col-4 col-sm-2 align-self-center">
<a href="/team/jjablonski/"><img loading="lazy" src="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/jjablonksi-avatar.e37c4f83308e.jpg&amp;w=800&amp;h=800&amp;mode=crop&amp;sig=c363b704eeccb35f2247db13baff3d4383459858" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/jjablonksi-avatar.e37c4f83308e.jpg&amp;w=200&amp;h=200&amp;mode=crop&amp;sig=706b16de3cb88a8f353f4a98d7c7bc7234229bd0 200w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/jjablonksi-avatar.e37c4f83308e.jpg&amp;w=400&amp;h=400&amp;mode=crop&amp;sig=6d7aa672ca3f1ac5f7cd62ed1641b60f98d04d8b 400w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/jjablonksi-avatar.e37c4f83308e.jpg&amp;w=800&amp;h=800&amp;mode=crop&amp;sig=c363b704eeccb35f2247db13baff3d4383459858 800w" sizes="10vw" width="240" height="240" class="rounded-circle img-fluid w-100" alt="Joanna Jablonski"></a>
</div>
<div class="col pl-0 d-none d-sm-block">
<a href="/team/jjablonski/" class="card-link small"><p>Joanna</p></a>
</div>
<div class="col-4 col-sm-2 align-self-center">
<a href="/team/kstratis/"><img loading="lazy" src="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/KEK9iuEG_400x400.28b60a4581c0.jpg&amp;w=400&amp;h=400&amp;mode=crop&amp;sig=445d048c1ba88637a77de71092496a250141f2ad" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/KEK9iuEG_400x400.28b60a4581c0.jpg&amp;w=100&amp;h=100&amp;mode=crop&amp;sig=1c5d57af62efdd49667bc93847c33a7118231efd 100w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/KEK9iuEG_400x400.28b60a4581c0.jpg&amp;w=200&amp;h=200&amp;mode=crop&amp;sig=6577ad9dd8206f0d84d34809b0d97731a9027693 200w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/KEK9iuEG_400x400.28b60a4581c0.jpg&amp;w=400&amp;h=400&amp;mode=crop&amp;sig=445d048c1ba88637a77de71092496a250141f2ad 400w" sizes="10vw" width="240" height="240" class="rounded-circle img-fluid w-100" alt="Kyle Stratis"></a>
</div>
<div class="col pl-0 d-none d-sm-block">
<a href="/team/kstratis/" class="card-link small"><p>Kyle</p></a>
</div>
</div>
</div>
</div>
</div>
<div class="bg-light rounded py-4 my-4 shadow shadow-sm mx-n2">
<div class="col-12 text-center d-block d-md-none">
<p class="h2 mb-3">Master <u><span class="marker-highlight">Real-World Python Skills</mark></u> With Unlimited Access to Real&nbsp;Python</p>
<p class="mb-1"><img class="w-75" src="https://cdn.realpython.com/static/videos/lesson-locked.f5105cfd26db.svg" width="510" height="260"></p>
<p class="mx-auto w-75 mb-3 small"><strong>Join us and get access to hundreds of tutorials, hands-on video courses, and a community of expert&nbsp;Pythonistas:</strong></p>
<p class="mb-0"><a href="/account/join/?utm_source=rp_article_footer&utm_content=linear-regression-in-python" class="btn btn-primary btn-sm px-4 mb-0">Level Up Your Python Skills »</a>
</div>
<div class="col-12 text-center d-none d-md-block">
<p class="h2 mb-2">Master <u><span class="marker-highlight">Real-World Python Skills</span></u><br>With Unlimited Access to Real&nbsp;Python</p>
<p class="mb-2"><img class="w-50 mb-2" src="https://cdn.realpython.com/static/videos/lesson-locked.f5105cfd26db.svg" width="510" height="260"></p>
<p class="mx-auto w-50 mb-3"><strong>Join us and get access to hundreds of tutorials, hands-on video courses, and a community of expert Pythonistas:</strong></p>
<p><a href="/account/join/?utm_source=rp_article_footer&utm_content=linear-regression-in-python" class="btn btn-primary btn-lg px-4">Level Up Your Python Skills »</a>
</div>
</div>
<div class="card mt-4" id="reader-comments">
<p class="card-header h3">What Do You Think?</p>
<div class="text-center mt-3 mb-0 p-0">
<span>
<a target="_blank" rel="nofollow" href="https://twitter.com/intent/tweet/?text=Check out this %23Python tutorial: Linear%20Regression%20in%20Python by @realpython&url=https%3A//realpython.com/linear-regression-in-python/" class="mr-1 badge badge-twitter text-light mb-1"><i class="mr-1 fa fa-twitter text-light"></i>Tweet</a>
<a target="_blank" rel="nofollow" href="https://facebook.com/sharer/sharer.php?u=https%3A//realpython.com/linear-regression-in-python/" class="mr-1 badge badge-facebook text-light mb-1"><i class="mr-1 fa fa-facebook text-light"></i>Share</a>
<a target="_blank" rel="nofollow" href="mailto:?subject=Python article for you&body=Check out this Python tutorial:%0A%0ALinear%20Regression%20in%20Python%0A%0Ahttps%3A//realpython.com/linear-regression-in-python/" class="badge badge-red text-light mb-1"><i class="mr-1 fa fa-envelope text-light"></i>Email</a>
</span>
</div>
<div class="card-body">
<div class="alert alert-dark">
<p class="mb-0"><strong>Real Python Comment Policy:</strong> The most useful comments are those written with the goal of learning from or helping out other readers—after reading the whole article and all the earlier comments. Complaints and insults generally won’t make the cut here.</p>
</div>
<p>What’s your #1 takeaway or favorite thing you learned? How are you going to put your newfound skills to use? Leave a comment below and let us know.</p>
<div class="mb-4" id="disqus_thread">
</div>
</div>
</div>
<div class="card mt-4 mb-4">
<p class="card-header h3">Keep Learning</p>
<div class="card-body">
<p class="mb-0">Related Tutorial Categories:
<a href="/tutorials/data-science/" class="badge badge-light text-muted">data-science</a>
<a href="/tutorials/intermediate/" class="badge badge-light text-muted">intermediate</a>
<a href="/tutorials/machine-learning/" class="badge badge-light text-muted">machine-learning</a>
</p>
</div>
</div>
<div class="modal fade" tabindex="-1" role="dialog" id="rprw">
<div class="modal-dialog modal-lg modal-dialog-centered" role="document">
<div class="modal-content">
<div class="modal-header border-0 mt-3">
<div class="col-12 modal-title text-center">
<h2 class="my-0 mx-5">Keep reading Real&nbsp;Python by creating a free account or signing&nbsp;in:</h2>
</div>
</div>
<div class="modal-body bg-light">
<div class="col-12 text-center">
<p class="mb-2 mt-3"><a href="/account/signup/?intent=continue_reading&utm_source=rp&utm_medium=web&utm_campaign=rwn&utm_content=v1&next=%2Flinear-regression-in-python%2F"><img class="w-50 mb-2" src="https://cdn.realpython.com/static/videos/lesson-locked.f5105cfd26db.svg" width="510" height="260" alt="Keep reading"></a></p>
<p><a href="/account/signup/?intent=continue_reading&utm_source=rp&utm_medium=web&utm_campaign=rwn&utm_content=v1&next=%2Flinear-regression-in-python%2F" class="btn btn-primary btn-lg px-5"></i>Continue »</a></a>
</div>
</div>
<div class="modal-footer border-0">
<p class="text-center text-muted mt-2 mb-1">Already have an account? <a href="/account/login/?next=/linear-regression-in-python/">Sign-In</a></p>
</div>
</div>
</div>
</div>
<script src="https://cdn.realpython.com/static/frontend/reader/rw.38bf29157dfe.js" async></script>
</div>
<aside class="col-md-7 col-lg-4">
<div class="card mb-3 bg-secondary">
<form class="card-body" action="/optins/process/" method="post">
<div class="form-group">
<p class="h5 text-muted text-center">— FREE Email Series —</p>
<p class="h3 text-center">🐍 Python Tricks 💌</p>
<p><img class="img-fluid rounded" src="https://cdn.realpython.com/static/pytrick-dict-merge.4201a0125a5e.png" width="738" height="490" alt="Python Tricks Dictionary Merge"></p>
</div>
<div class="form-group">
<input type="hidden" name="csrfmiddlewaretoken" value="6VxoFY4jQ9ftCnk0Kv5ORe4tyyfmrrnxc0cBgxghbEaDMgZIThxYhj3pOtkgEZRm">
<input type="hidden" name="slug" value="static-python-tricks-sidebar">
<input type="email" class="form-control form-control-md" name="email" placeholder="Email&hellip;" required>
</div>
<button type="submit" name="submit" class="btn btn-primary btn-md btn-block">Get Python Tricks »</button>
<p class="mb-0 mt-2 text-muted text-center">🔒 No spam. Unsubscribe any time.</p>
</form>
</div>
<div class="sidebar-module sidebar-module-inset border">
<p class="h4"><a class="link-unstyled" href="/tutorials/all/">All Tutorial Topics</a></p>
<a href="/tutorials/advanced/" class="badge badge-light text-muted">advanced</a>
<a href="/tutorials/api/" class="badge badge-light text-muted">api</a>
<a href="/tutorials/basics/" class="badge badge-light text-muted">basics</a>
<a href="/tutorials/best-practices/" class="badge badge-light text-muted">best-practices</a>
<a href="/tutorials/community/" class="badge badge-light text-muted">community</a>
<a href="/tutorials/databases/" class="badge badge-light text-muted">databases</a>
<a href="/tutorials/data-science/" class="badge badge-light text-muted">data-science</a>
<a href="/tutorials/devops/" class="badge badge-light text-muted">devops</a>
<a href="/tutorials/django/" class="badge badge-light text-muted">django</a>
<a href="/tutorials/docker/" class="badge badge-light text-muted">docker</a>
<a href="/tutorials/flask/" class="badge badge-light text-muted">flask</a>
<a href="/tutorials/front-end/" class="badge badge-light text-muted">front-end</a>
<a href="/tutorials/gamedev/" class="badge badge-light text-muted">gamedev</a>
<a href="/tutorials/gui/" class="badge badge-light text-muted">gui</a>
<a href="/tutorials/intermediate/" class="badge badge-light text-muted">intermediate</a>
<a href="/tutorials/machine-learning/" class="badge badge-light text-muted">machine-learning</a>
<a href="/tutorials/projects/" class="badge badge-light text-muted">projects</a>
<a href="/tutorials/python/" class="badge badge-light text-muted">python</a>
<a href="/tutorials/testing/" class="badge badge-light text-muted">testing</a>
<a href="/tutorials/tools/" class="badge badge-light text-muted">tools</a>
<a href="/tutorials/web-dev/" class="badge badge-light text-muted">web-dev</a>
<a href="/tutorials/web-scraping/" class="badge badge-light text-muted">web-scraping</a>
</div>
<div class="sidebar-module sidebar-module-inset p-0" style="overflow:hidden;">
<div style="display:block;position:relative;">
<div style="display:block;width:100%;padding-top:100%;"></div>
<div class="rpad" data-unit="1x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div>
</div>
</div>
<div class="sidebar-sticky ">
<div class="bg-light sidebar-module sidebar-module-inset" id="sidebar-toc">
<p class="h4 text-muted"><a class="link-unstyled" href="#toc">Table of Contents</a></p>
<div class="toc">
<ul>
<li><a href="#regression">Regression</a><ul>
<li><a href="#what-is-regression">What Is Regression?</a></li>
<li><a href="#when-do-you-need-regression">When Do You Need Regression?</a></li>
</ul>
</li>
<li><a href="#linear-regression">Linear Regression</a><ul>
<li><a href="#problem-formulation">Problem Formulation</a></li>
<li><a href="#regression-performance">Regression Performance</a></li>
<li><a href="#simple-linear-regression">Simple Linear Regression</a></li>
<li><a href="#multiple-linear-regression">Multiple Linear Regression</a></li>
<li><a href="#polynomial-regression">Polynomial Regression</a></li>
<li><a href="#underfitting-and-overfitting">Underfitting and Overfitting</a></li>
</ul>
</li>
<li><a href="#implementing-linear-regression-in-python">Implementing Linear Regression in Python</a><ul>
<li><a href="#python-packages-for-linear-regression">Python Packages for Linear Regression</a></li>
<li><a href="#simple-linear-regression-with-scikit-learn">Simple Linear Regression With scikit-learn</a></li>
<li><a href="#multiple-linear-regression-with-scikit-learn">Multiple Linear Regression With scikit-learn</a></li>
<li><a href="#polynomial-regression-with-scikit-learn">Polynomial Regression With scikit-learn</a></li>
<li><a href="#advanced-linear-regression-with-statsmodels">Advanced Linear Regression With statsmodels</a></li>
</ul>
</li>
<li><a href="#beyond-linear-regression">Beyond Linear Regression</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</div>
</div>
<div class="sidebar-module sidebar-module-inset text-center my-3 py-0">
<div class="jsCompletionStatusWidget btn-group mb-0">
<button title="Click to mark as completed" class="jsBtnCompletion btn btn-secondary border-right " style="border-top-right-radius: 0; border-bottom-right-radius: 0;" disabled>Mark as Completed</button>
<button title="Add bookmark" class="jsBtnBookmark btn btn-secondary border-left" disabled><i class="fa fa-fw fa-bookmark-o"></i></button>
</div>
</div>
<div class="sidebar-module sidebar-module-inset text-center my-3 py-0">
<span>
<a target="_blank" rel="nofollow" href="https://twitter.com/intent/tweet/?text=Check out this %23Python tutorial: Linear%20Regression%20in%20Python by @realpython&url=https%3A//realpython.com/linear-regression-in-python/" class="mr-1 badge badge-twitter text-light mb-1"><i class="mr-1 fa fa-twitter text-light"></i>Tweet</a>
<a target="_blank" rel="nofollow" href="https://facebook.com/sharer/sharer.php?u=https%3A//realpython.com/linear-regression-in-python/" class="mr-1 badge badge-facebook text-light mb-1"><i class="mr-1 fa fa-facebook text-light"></i>Share</a>
<a target="_blank" rel="nofollow" href="mailto:?subject=Python article for you&body=Check out this Python tutorial:%0A%0ALinear%20Regression%20in%20Python%0A%0Ahttps%3A//realpython.com/linear-regression-in-python/" class="badge badge-red text-light mb-1"><i class="mr-1 fa fa-envelope text-light"></i>Email</a>
</span>
</div>
<div class="sidebar-module sidebar-module-inset p-0" style="overflow:hidden;">
<div style="display:block;position:relative;">
<div style="display:block;width:100%;padding-top:25%;"></div>
<div class="rpad" data-unit="4x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div>
</div>
</div>
</div>
</aside>
</div>
</div>
<div class="modal fade" id="modal-numpy-learning-guide" tabindex="-1" role="dialog" aria-hidden="true">
<div class="modal-dialog modal-dialog-centered modal-lg" role="document">
<div class="modal-content">
<div class="modal-header bg-light pt-3 pb-2">
<div class="container-fluid">
<div class="row">
<div class="col-12">
<div class="progress" style="height: .5rem;">
<div class="progress-bar progress-bar-striped progress-bar-animated w-50" role="progressbar"></div>
</div>
</div>
<div class="col-12">
<p class="text-muted text-center mb-0 mt-2">Almost there! Complete this form and click the button below to gain instant access:</p>
</div>
</div>
</div>
<button type="button" class="close" data-dismiss="modal" aria-label="Close">
<span aria-hidden="true">&times;</span>
</button>
</div>
<div class="modal-body m-4">
<div class="container-fluid">
<div class="row align-items-center">
<div class="col-12 col-lg-4 mb-4">
<img class="img-fluid rounded" src="https://files.realpython.com/media/numpy-learning-guide.71182b4d845c.jpg" width="700" height="494" srcset="https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/numpy-learning-guide.71182b4d845c.jpg&amp;w=175&amp;sig=3b73bcdd0c2a8928222686a9a1b44bcc770e722b 175w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/numpy-learning-guide.71182b4d845c.jpg&amp;w=350&amp;sig=207a8a83e872fd56c8040cf13b4d903beecb2249 350w, https://files.realpython.com/media/numpy-learning-guide.71182b4d845c.jpg 700w" sizes="50vw" alt="NumPy Learning Resources Guide">
</div>
<div class="col">
<p class="text-center h3 mb-4">NumPy: The Best Learning Resources (A Free PDF Guide)</p>
<form class="col-12" action="/optins/process/" method="post">
<input type="hidden" name="csrfmiddlewaretoken" value="6VxoFY4jQ9ftCnk0Kv5ORe4tyyfmrrnxc0cBgxghbEaDMgZIThxYhj3pOtkgEZRm">
<input type="hidden" name="slug" value="numpy-learning-guide">
<div class="form-group">
<input type="email" name="email" class="form-control" placeholder="Email Address" required autofocus>
</div>
<button name="submit" type="submit" class="btn btn-primary btn-block text-wrap">Send My NumPy Guide »</button>
</form>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<footer class="footer">
<div class="container">
<div class="w-75 mx-auto mt-4 mb-0">
<div style="display:block;position:relative;">
<div style="display:block;width:100%;padding-top:12.5%;"></div>
<div class="rpad rounded border" data-unit="8x1" style="position:absolute;left:0;top:0;right:0;bottom:0;overflow:hidden;"></div>
</div>
<a class="small text-muted" href="/account/join/" rel="nofollow"> <i class="fa fa-info-circle" aria-hidden="true"> </i> Remove ads</a>
</div>
<p class="text-center text-muted w-75 mx-auto">© 2012–2021 Real Python&nbsp;⋅ <a href="/newsletter/">Newsletter</a>&nbsp;⋅ <a href="/podcasts/rpp/">Podcast</a>&nbsp;⋅ <a href="https://www.youtube.com/realpython">YouTube</a>&nbsp;⋅ <a href="https://twitter.com/realpython">Twitter</a>&nbsp;⋅ <a href="https://facebook.com/LearnRealPython">Facebook</a>&nbsp;⋅ <a href="https://www.instagram.com/realpython/">Instagram</a>&nbsp;⋅ <a href="/">Python&nbsp;Tutorials</a>&nbsp;⋅ <a href="/search">Search</a>&nbsp;⋅ <a href="/privacy-policy/">Privacy Policy</a>&nbsp;⋅ <a href="/energy-policy/" class="text-success active">Energy Policy</a>&nbsp;⋅ <a href="/sponsorships/">Advertise</a>&nbsp;⋅ <a href="/contact/">Contact</a><br>❤️ Happy Pythoning!</p>
</div>
</footer>
<script>
      (function(document, history, location) {
        var HISTORY_SUPPORT = !!(history && history.pushState);

        var anchorScrolls = {
          ANCHOR_REGEX: /^#[^ ]+$/,
          OFFSET_HEIGHT_PX: 120,

          /**
           * Establish events, and fix initial scroll position if a hash is provided.
           */
          init: function() {
            this.scrollToCurrent();
            window.addEventListener('hashchange', this.scrollToCurrent.bind(this));
            document.body.addEventListener('click', this.delegateAnchors.bind(this));
          },

          /**
           * Return the offset amount to deduct from the normal scroll position.
           * Modify as appropriate to allow for dynamic calculations
           */
          getFixedOffset: function() {
            return this.OFFSET_HEIGHT_PX;
          },

          /**
           * If the provided href is an anchor which resolves to an element on the
           * page, scroll to it.
           * @param  {String} href
           * @return {Boolean} - Was the href an anchor.
           */
          scrollIfAnchor: function(href, pushToHistory) {
            var match, rect, anchorOffset;

            if(!this.ANCHOR_REGEX.test(href)) {
              return false;
            }

            match = document.getElementById(href.slice(1));

            if(match) {
              rect = match.getBoundingClientRect();
              anchorOffset = window.pageYOffset + rect.top - this.getFixedOffset();
              window.scrollTo(window.pageXOffset, anchorOffset);

              // Add the state to history as-per normal anchor links
              if(HISTORY_SUPPORT && pushToHistory) {
                history.pushState({}, document.title, location.pathname + href);
              }
            }

            return !!match;
          },

          /**
           * Attempt to scroll to the current location's hash.
           */
          scrollToCurrent: function() {
            this.scrollIfAnchor(window.location.hash);
          },

          /**
           * If the click event's target was an anchor, fix the scroll position.
           */
          delegateAnchors: function(e) {
            var elem = e.target;

            if(
              elem.nodeName === 'A' &&
              this.scrollIfAnchor(elem.getAttribute('href'), true)
            ) {
              e.preventDefault();
            }
          }
        };

        window.addEventListener(
          'DOMContentLoaded', anchorScrolls.init.bind(anchorScrolls)
        );
      })(window.document, window.history, window.location);
    </script>
<script src="https://cdn.realpython.com/static/jquery.min.8fb8fee4fcc3.js"></script>
<script src="https://cdn.realpython.com/static/popper.min.1022eaf388cc.js"></script>
<script src="https://cdn.realpython.com/static/bootstrap.min.f0c2bcf5ef0c.js"></script>
<script>
    (function() {
      document.querySelectorAll(".js-search-form-submit").forEach(function(el) {
        el.addEventListener("click", function(e) {
          e.preventDefault();
          e.currentTarget.parentElement.submit();
        })
      });
    })();
    </script>
<script src="https://cdn.realpython.com/static/frontend/reader/repl-toggle.de6c7bf44788.js" async></script>
<script src="https://cdn.realpython.com/static/frontend/reader/lightbox.49cdac39212e.js" async></script>
<script>window.rp_prop_id = '58946116052';</script>
<script src="https://srv.realpython.net/tag.js" async></script>
<script src="https://cdn.realpython.com/static/frontend/reader/toc-refresh.76a102c7d921.js" async></script>
<script id="js-context" type="application/json">{"is_completed": false, "is_bookmarked": false, "api_article_bookmark_url": "/api/v1/articles/linear-regression-in-python/bookmark/", "api_article_completion_status_url": "/api/v1/articles/linear-regression-in-python/completion_status/"}</script>
<script src="https://cdn.realpython.com/static/frontend/reader/completion-status.352d07abd84a.js" async></script>
<script id="dsq-count-scr" src="https://realpython.disqus.com/count.js" async></script>
<script>
      var disqus_config = function () {
        this.page.url = 'https://realpython.com/linear-regression-in-python/';
        this.page.identifier = 'https://realpython.com/linear-regression-in-python/';
        this.callbacks.onReady = [function() {
          if (window.onDisqusReady) {
            window.onDisqusReady();
          }
        }];
      };
      var disqus_script_url = 'https://realpython.disqus.com/embed.js';
    </script>
<script src="https://cdn.realpython.com/static/frontend/reader/lazy-disqus.07ee9079f4a3.js" defer></script>
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "Article",
    "headline": "Linear Regression in Python",
    
    "image": {
      "@type": "ImageObject",
      "url": "https://files.realpython.com/media/Linear-Regression-in-Python_Watermarked.479f82188ace.jpg",
      "width": 1920,
      "height": 1080
    },
    
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://realpython.com/linear-regression-in-python/"
    },
    "datePublished": "2019-04-15T14:00:00+00:00",
    "dateModified": "2021-03-19T05:23:23.544289+00:00",
     "publisher": {
      "@type": "Organization",
      "name": "Real Python",
      "logo": {
        "@type": "ImageObject",
        "url": "https://cdn.realpython.com/static/real-python-logo-square-tiny.b2452b6d3823.png",
        "width": 60,
        "height": 60
      }
    },
    "author": {
      "@type": "Organization",
      "name": "Real Python",
      "url": "https://realpython.com",
      "logo": "https://cdn.realpython.com/static/real-python-logo-square.146e987bf77c.png"
    },
    "description": "In this step\u002Dby\u002Dstep tutorial, you\u0027ll get started with linear regression in Python. Linear regression is one of the fundamental statistical and machine learning techniques, and Python is a popular choice for machine learning."
  }
  </script>
<script>
  var _dcq = _dcq || [];
  var _dcs = _dcs || {};
  _dcs.account = '6214500';

  (function() {
    var dc = document.createElement('script');
    dc.type = 'text/javascript'; dc.async = true;
    dc.src = '//tag.getdrip.com/6214500.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(dc, s);
  })();
</script>
<script type="text/javascript">(function(){window['__CF$cv$params']={r:'694a45a2ddf83749',m:'SdeB7A4ceGF6AozY0VMWVb8AOXwPKpFqveLT0hoB1BY-1632636027-0-AdqBJmOVx3CC8ogEnwIl7V/uEV7iLCB1/Uj04R4D4W7FYG9UeNz/uS6Cwa3KQ/Y5j3yJ7RFuzQ2+KhO3K8tz9fK0MHbMBgbrbdZoowH/miZ+8HqIYBjqTW5LaBHZ+l/hF+L1yzptWfjsr/sRchTBkmc=',s:[0x036c1a9cf4,0x94919ed8a6],u:'/cdn-cgi/challenge-platform/h/b'}})();</script></body>
</html>
